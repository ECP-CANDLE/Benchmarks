[Global_Params]
model_name = 'p3b9'
output_dir = './outputs/'
train_bool = True
per_device_train_batch_size = 12
gradient_accumulation_steps = 1
max_len = 512
learning_rate = 1e-4
weight_decay = 0.0000
adam_beta2 = 0.98
adam_epsilon = 2e-8
max_steps = 10
warmup_steps = 1
token_max_len = 128
vocab_size = 30_000
hidden_size = 768
intermediate_size = 3072
max_position_embeddings = 512
num_attention_heads = 12
num_hidden_layers = 12
type_vocab_size = 2
